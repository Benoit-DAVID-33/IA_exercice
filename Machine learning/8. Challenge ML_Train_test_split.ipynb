{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RZbCjBZBNKL"
      },
      "source": [
        "# Execute the code below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ih5VsCSsAGWK"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "from sklearn.linear_model import LinearRegression\n",
        "link = \"https://raw.githubusercontent.com/LucaSainteCroix/teaching-resources/main/exercises-data/weather2019.csv\"\n",
        "df_weather = pd.read_csv(link)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDfmi_gNBRd3"
      },
      "source": [
        "# Scoring and metrics\n",
        "Last time, you did a multivariate linear regression. But how can you be sure this multivariate linear regression is better than an univariate ? You have to measure it !\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gs0tr5sYgvwI"
      },
      "source": [
        "## First regression\n",
        "Let's begin with a first linear regression : create a new column `'predict_from_sun'` whith the prediction of MAX temperature from the SUNHOUR variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "h0u82y2paa75"
      },
      "outputs": [],
      "source": [
        "# Your code here :\n",
        "X = df_weather[['MAX_TEMPERATURE_C']]\n",
        "y = df_weather[['SUNHOUR']]\n",
        "\n",
        "model_from_sun = LinearRegression().fit(X, y)\n",
        "\n",
        "df_weather['predict_from_sun'] = model_from_sun.predict(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaSRoaFdgu23"
      },
      "source": [
        "## R2 score\n",
        "The best possible R2 score is '1', when our prediction predicts perfectly the reality. Let's see what is our R2 score :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bhI2x_Z-g-lM"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.4765455405908732"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Change the name of the model if it's necessary\n",
        "model_from_sun.score(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPYPIs6kgWq2"
      },
      "source": [
        "## Let's continue with 2 others regressions\n",
        "- Second regression : create a new column 'predict_from_min' whith the prediction of MAX temperature from the MIN temperature variable\n",
        "- Third regression : create a new column 'predict_from_both' whith the prediction of MAX temperature from the both variables (MIN temperature and Sunhours)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0uWGISfxiGN_"
      },
      "outputs": [],
      "source": [
        "# Your code here :\n",
        "# df_weather['predict_from_min'] = model_from_sun.predict(X)\n",
        "\n",
        "X_min = df_weather[['MIN_TEMPERATURE_C']]\n",
        "y_min = df_weather['MAX_TEMPERATURE_C']\n",
        "\n",
        "model_from_min = LinearRegression()\n",
        "model_from_min.fit(X_min, y_min)\n",
        "\n",
        "df_weather['predict_from_min'] = model_from_min.predict(X_min)\n",
        "\n",
        "X_both = df_weather[['MIN_TEMPERATURE_C', 'SUNHOUR']]\n",
        "y_both = df_weather['MAX_TEMPERATURE_C']\n",
        "\n",
        "model_from_both = LinearRegression()\n",
        "model_from_both.fit(X_both, y_both)\n",
        "\n",
        "df_weather['predict_from_both'] = model_from_both.predict(X_both)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYVUuG97h0HO"
      },
      "source": [
        "## Calculate the R2 score of the 2 new predictions\n",
        "Be careful : if you still use the same \"X\" name, you will overwrite it.\n",
        "\n",
        "Which model has the best score ? Do you think it's logical ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "7lQObVxpe6uh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "R2 Score for predict_from_min: 0.7689396999057355\n",
            "R2 Score for predict_from_both: 0.8674787980774968\n",
            "R2 Score for predict_from_sun: 0.4765455405908732\n"
          ]
        }
      ],
      "source": [
        "# Your code here :\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Calculate R2 score for the model_from_min\n",
        "r2_score_from_min = r2_score(y_min, df_weather['predict_from_min'])\n",
        "print(f'R2 Score for predict_from_min: {r2_score_from_min}')\n",
        "\n",
        "# Calculate R2 score for the model_from_both\n",
        "r2_score_from_both = r2_score(y_both, df_weather['predict_from_both'])\n",
        "print(f'R2 Score for predict_from_both: {r2_score_from_both}')\n",
        "\n",
        "# # Calculate R2 score for the model_from_sun\n",
        "# r2_score_from_sun = r2_score(y, df_weather['predict_from_sun'])\n",
        "# print(f'R2 Score for predict_from_sun: {r2_score_from_sun}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1frFHshijXUK"
      },
      "source": [
        "# Train Test Split\n",
        "One of biggest problems of Machine learning is : **overfitting**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UCz7M7vknsY"
      },
      "source": [
        "To be sure that machine didn't memorize the result, we use the Train Test Split methodology. We keep some data separate (often 25% of our initial dataset). Then we train our model on the 75% (the \"Train set\").\n",
        "After, we can calculate a score on the \"Test set\".\n",
        "\n",
        "Let's do that !"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "EKIttez3pFou"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The length of the initial dataset is : 365\n",
            "The length of the train dataset is   : 273\n",
            "The length of the test dataset is    : 92\n",
            "\n",
            "Score for the Train dataset : 0.47243569075679914\n",
            "Score for the Test dataset : 0.4749360350733982\n"
          ]
        }
      ],
      "source": [
        "# Juste read and execute the code below\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df_weather[['SUNHOUR']]\n",
        "y = df_weather['MAX_TEMPERATURE_C']\n",
        "\n",
        "# Here, we split our 2 datasets (the variables \"X\" and the target \"y\") into 4 datasets X and y for the train set and X and y for the test set.\n",
        "# We set the size of the train set to 75%. And the rest is for the test set.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, train_size = 0.75)\n",
        "print(\"The length of the initial dataset is :\", len(X))\n",
        "print(\"The length of the train dataset is   :\", len(X_train))\n",
        "print(\"The length of the test dataset is    :\", len(X_test))\n",
        "\n",
        "# Here we train the model only on the train dataset.\n",
        "newmodel = LinearRegression().fit(X_train, y_train)\n",
        "\n",
        "# And now we compare both scores :\n",
        "print(\"\\nScore for the Train dataset :\", newmodel.score(X_train, y_train))\n",
        "print(\"Score for the Test dataset :\", newmodel.score(X_test, y_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwetw4TfsHEJ"
      },
      "source": [
        "## Both scores are very close, there is no overfitting, well done !\n",
        "\n",
        "What happens if we don't randomize our dataset. Here, the model learns only on the 9 first months."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "xsusD6mEuE36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Score for the Train dataset : 0.7875765302008688\n",
            "Score for the Test dataset : 0.03610833322378626\n"
          ]
        }
      ],
      "source": [
        "# Juste read and execute the code below\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df_weather[['MIN_TEMPERATURE_C']]\n",
        "y = df_weather['MAX_TEMPERATURE_C']\n",
        "\n",
        "# We set the size of the train set to 75%. And the rest is for the test set.\n",
        "# We set the split NOT in random.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.75, shuffle = False)\n",
        "\n",
        "\n",
        "# Here we train the model only on the train dataset.\n",
        "newmodel = LinearRegression().fit(X_train, y_train)\n",
        "\n",
        "# And now we compare both scores :\n",
        "print(\"\\nScore for the Train dataset :\", newmodel.score(X_train, y_train))\n",
        "print(\"Score for the Test dataset :\", newmodel.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vrIsw55vNM6"
      },
      "source": [
        "## There is an overfitting !\n",
        "Indeed, the model get a good score on the Train dataset, because he learned in winter / spring / summer datas. But he gets a bad score in Falls..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "652oRHFcwI0H"
      },
      "source": [
        "# Let's play !\n",
        "Train a new model with all numeric variables (without your target of course) and try to have a better score than previously.\n",
        "\n",
        "Remember to split randomly your dataset before training your model.\n",
        "\n",
        "Display the Test score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "nR-dmy-LxNtZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Score for the Train dataset with all numeric variables: 0.9932998846984684\n",
            "Score for the Test dataset with all numeric variables: 0.9953355475913898\n"
          ]
        }
      ],
      "source": [
        "# Your code here :\n",
        "X = df_weather[['MIN_TEMPERATURE_C', 'WINDSPEED_MAX_KMH', 'TEMPERATURE_MORNING_C', 'TEMPERATURE_NOON_C', \n",
        "                'TEMPERATURE_EVENING_C', 'PRECIP_TOTAL_DAY_MM', 'HUMIDITY_MAX_PERCENT', 'VISIBILITY_AVG_KM',        \n",
        "                'PRESSURE_MAX_MB', 'CLOUDCOVER_AVG_PERCENT', 'HEATINDEX_MAX_C', 'DEWPOINT_MAX_C', 'WINDTEMP_MAX_C',\n",
        "                'TOTAL_SNOW_MM', 'SUNHOUR', 'MONTH', 'DAY']]\n",
        "\n",
        "# X_all_numeric = df_weather.select_dtypes(include='number').drop('MAX_TEMPERATURE_C', axis=1)\n",
        "y_all_numeric = df_weather['MAX_TEMPERATURE_C']\n",
        "\n",
        "# Splitting the dataset randomly\n",
        "X_train_all, X_test_all, y_train_all, y_test_all = train_test_split(X, y_all_numeric, test_size=0.25, random_state=42)\n",
        "\n",
        "new_model_all_numeric = LinearRegression().fit(X_train_all, y_train_all)\n",
        "\n",
        "print(\"\\nScore for the Train dataset with all numeric variables:\", new_model_all_numeric.score(X_train_all, y_train_all))\n",
        "print(\"Score for the Test dataset with all numeric variables:\", new_model_all_numeric.score(X_test_all, y_test_all))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
