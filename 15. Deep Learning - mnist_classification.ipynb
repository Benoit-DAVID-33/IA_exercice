{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéØ <b><u>Exercise objectives</u></b>\n",
    "- Understand the *MNIST* dataset \n",
    "- Design your first **Convolutional Neural Network** (*CNN*) and answer questions such as:\n",
    "    - what are *Convolutional Layers*? \n",
    "    - how many *parameters* are involved in such a layer?\n",
    "- Train this CNN on images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üöÄ <b><u>Let's get started!</u></b>\n",
    "\n",
    "Imagine that we are  back in time into the 90's.\n",
    "You work at a *Post Office* and you have to deal with an enormous amount of letters on a daily basis. How could you automate the process of reading the ZIP Codes, which are a combination of 5 handwritten digits? \n",
    "\n",
    "This task, called the **Handwriting Recognition**, used to be a very complex problem back in those days. It was solved by *Bell Labs* (among others) where one of the Deep Learning gurus, [*Yann Le Cun*](https://en.wikipedia.org/wiki/Yann_LeCun), used to work.\n",
    "\n",
    "From [Wikipedia](https://en.wikipedia.org/wiki/Handwriting_recognition):\n",
    "\n",
    "> Handwriting recognition (HWR), also known as Handwritten Text Recognition (HTR), is the ability of a computer to receive and interpret intelligible handwritten input from sources such as paper documents, photographs, touch-screens and other devices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ü§î <b><u>How does this CNN work ?</u></b>\n",
    "\n",
    "- *Inputs*: Images (_each image shows a handwritten digit_)\n",
    "- *Target*: For each image, you want your CNN model to predict the correct digit (between 0 and 9)\n",
    "    - It is a **multi-class classification** task (more precisely a 10-class classification task since there are 10 different digits).\n",
    "\n",
    "üî¢ To improve the capacity of the Convolutional Neural Network to read these numbers, we need to feed it with many images representing handwritten digits. This is why the üìö [**MNIST dataset**](http://yann.lecun.com/exdb/mnist/) *(Mixed National Institute of Standards and Technology)* was created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) The `MNIST` Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìö Tensorflow/Keras offers multiple [**datasets**](https://www.tensorflow.org/api_docs/python/tf/keras/datasets) to play with:\n",
    "- *Vectors*: `boston_housing` (regression)\n",
    "- *Images* : `mnist`, `fashion_mnist`, `cifar10`, `cifar100` (classification)\n",
    "- *Texts*: `imbd`, `reuters` (classification/sentiment analysis)\n",
    "\n",
    "\n",
    "üíæ You can **load the MNIST dataset** with the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\benoi\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 5s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(((60000, 28, 28), (60000,)), ((10000, 28, 28), (10000,)))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import datasets\n",
    "\n",
    "\n",
    "# Loading the MNIST Dataset...\n",
    "(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data(path=\"mnist.npz\")\n",
    "\n",
    "# The train set contains 60 000 images, each of them of size 28x28\n",
    "# The test set contains 10 000 images, each of them of size 28x28\n",
    "(X_train.shape, y_train.shape), (X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.1) Exploring the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question: Let's have look at some handwritten digits of this MNIST dataset.** ‚ùì\n",
    "\n",
    "üñ® Print some images from the *train set*.\n",
    "\n",
    "<details>\n",
    "    <summary><i>Hints</i></summary>\n",
    "\n",
    "üí°*Hint*: use the `imshow` function from `matplotlib` with `cmap = \"gray\"`\n",
    "\n",
    "ü§® Note: if you don't specify this *cmap* argument, the weirdly displayed colors are just Matplotlib defaults...\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Charger l'ensemble de donn√©es MNIST\n",
    "(train_images, train_labels), _ = mnist.load_data()\n",
    "\n",
    "# Afficher quelques images du jeu d'entra√Ænement\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(5):  # Afficher les 5 premi√®res images\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plt.imshow(train_images[i], cmap='gray')\n",
    "    plt.title(f\"Label: {train_labels[i]}\")\n",
    "    plt.axis('off')  # D√©sactiver les axes\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.2) Image Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùóÔ∏è **Neural Networks converge faster when the input data is somehow normalized** ‚ùóÔ∏è\n",
    "\n",
    "üë©üèª‚Äçüè´ How do we proceed for Convolutional Neural Networks ?\n",
    "* The `RBG` intensities are coded between 0 and 255. \n",
    "* We can simply divide the input data by the maximal value 255 to have all the pixels' intensities between 0 and 1 üòâ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question ‚ùì As a first preprocessing step, please normalize your data.** \n",
    "\n",
    "Don't forget to do it both on your train data and your test data.\n",
    "\n",
    "(*Note: you can also center your data, by subtracting 0.5 from all the values, but it is not mandatory*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normaliser les donn√©es en les divisant par 255\n",
    "train_images_normalized = train_images / 255.0\n",
    "test_images_normalized = test_images / 255.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.3) Inputs' dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëÜ Remember that you have 60,000 training images and 10,000 test images, each of size $(28, 28)$. However...\n",
    "\n",
    "> ‚ùóÔ∏è  **`Convolutional Neural Network models need to be fed with images whose last dimension is the number of channels`.**  \n",
    "\n",
    "> üßëüèª‚Äçüè´ The shape of tensors fed into ***ConvNets*** is the following: `(NUMBER_OF_IMAGES, HEIGHT, WIDTH, CHANNELS)`\n",
    "\n",
    "üïµüèªThis last dimension is clearly missing here. Can you guess the reason why?\n",
    "<br>\n",
    "<details>\n",
    "    <summary><i>Answer<i></summary>\n",
    "        \n",
    "* All these $60000$ $ (28 \\times 28) $ pictures are black-and-white $ \\implies $ Each pixel lives on a spectrum from full black (0) to full white (1).\n",
    "        \n",
    "    * Theoretically, you don't need to know the number of channels for a black-and-white picture since there is only 1 channel (the \"whiteness\" of \"blackness\" of a pixel). However, it is still mandatory for the model to have this number of channels explicitly stated.\n",
    "        \n",
    "    * In comparison, colored pictures need multiple channels:\n",
    "        - the RGB system with 3 channels (<b><span style=\"color:red\">Red</span> <span style=\"color:green\">Green</span> <span style=\"color:blue\">Blue</span></b>)\n",
    "        - the CYMK system  with 4 channels (<b><span style=\"color:cyan\">Cyan</span> <span style=\"color:magenta\">Magenta</span> <span style=\"color:yellow\">Yellow</span> <span style=\"color:black\">Black</span></b>)\n",
    "        \n",
    "        \n",
    "</details>        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question: expanding dimensions** ‚ùì\n",
    "\n",
    "* Use the **`expand_dims`** to add one dimension at the end of the training data and test data.\n",
    "\n",
    "* Then, print the shapes of `X_train` and `X_test`. They should respectively be equal to $(60000, 28, 28, 1)$ and $(10000, 28, 28, 1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Charger l'ensemble de donn√©es MNIST\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normaliser les donn√©es en les divisant par 255\n",
    "train_images_normalized = train_images / 255.0\n",
    "test_images_normalized = test_images / 255.0\n",
    "\n",
    "# Ajouter une dimension √† la fin des donn√©es\n",
    "X_train = np.expand_dims(train_images_normalized, axis=-1)\n",
    "X_test = np.expand_dims(test_images_normalized, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (60000, 28, 28, 1)\n",
      "Shape of X_test: (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train:\", X_train.shape)  # Devrait √™tre (60000, 28, 28, 1)\n",
    "print(\"Shape of X_test:\", X_test.shape)    # Devrait √™tre (10000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.4) Target encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more thing to for a multiclass classification task in Deep Leaning:\n",
    "\n",
    "üëâ _\"one-hot-encode\" the categories*_\n",
    "\n",
    "‚ùì **Question: encoding the labels** ‚ùì \n",
    "\n",
    "* Use **`to_categorical`** to transform your labels. \n",
    "* Store the results into two variables that you can call **`y_train_cat`** and **`y_test_cat`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Charger l'ensemble de donn√©es MNIST\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Effectuer l'encodage one-hot des √©tiquettes\n",
    "y_train_cat = to_categorical(train_labels)\n",
    "y_test_cat = to_categorical(test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is now ready to be used. ‚úÖ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) The Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.1) Architecture and compilation of a CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "‚ùì **Question: CNN Architecture and compilation** ‚ùì\n",
    "\n",
    "Now, let's build a <u>Convolutional Neural Network</u> that has: \n",
    "\n",
    "\n",
    "- a `Conv2D` layer with 8 filters, each of size $(4, 4)$, an input shape suitable for your task, the `relu` activation function, and `padding='same'`\n",
    "- a `MaxPool2D` layer with a `pool_size` equal to $(2, 2)$\n",
    "- a second `Conv2D` layer with 16 filters, each of size $(3, 3)$, and the `relu` activation function\n",
    "- a second `MaxPool2D` layer with a `pool_size` equal to $(2, 2)$\n",
    "\n",
    "\n",
    "- a `Flatten` layer\n",
    "- a first `Dense` layer with 10 neurons and the `relu` activation function\n",
    "- a last (predictive) layer that is suited for your task\n",
    "\n",
    "In the function that initializes this model, do not forget to include the <u>compilation of the model</u>, which:\n",
    "* optimizes the `categorical_crossentropy` loss function,\n",
    "* with the `adam` optimizer, \n",
    "* and the `accuracy` as the metrics\n",
    "\n",
    "(*Note: you could add more classification metrics if you want but the dataset is well balanced!*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
    "\n",
    "\n",
    "def initialize_model():\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Couches de convolution\n",
    "    model.add(Conv2D(8, (4, 4), activation='relu', input_shape=(28, 28, 1), padding='same'))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Couches compl√®tement connect√©es\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation='relu'))  # Ajoutez cette ligne pour la couche Dense\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "  # Assurez-vous de remplacer NOMBRE_DE_CLASSES par le nombre appropri√© de classes\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question: number of trainable parameters in a convolutional layer** ‚ùì \n",
    "\n",
    "How many trainable parameters are there in your model?\n",
    "1. Compute them with ***model.summary( )*** first\n",
    "2. Recompute them manually to make sure you properly understood ***what influences the number of weights in a CNN***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 28, 28, 8)         136       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPoolin  (None, 14, 14, 8)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 12, 12, 16)        1168      \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPoolin  (None, 6, 6, 16)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 576)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5770      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7184 (28.06 KB)\n",
      "Trainable params: 7184 (28.06 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Nombre total de param√®tres dans le mod√®le : 1304\n"
     ]
    }
   ],
   "source": [
    "# Construire et compiler le mod√®le\n",
    "cnn_model = initialize_model()\n",
    "\n",
    "# Afficher le r√©sum√© du mod√®le pour calculer les param√®tres avec model.summary()\n",
    "cnn_model.summary()\n",
    "\n",
    "# Calcul manuel du nombre de param√®tres dans une couche Conv2D\n",
    "nombre_filtres_couche1 = 8\n",
    "taille_filtre_couche1 = (4, 4)\n",
    "nombre_canaux_entree_couche1 = 1  # Pour MNIST en niveaux de gris\n",
    "nombre_parametres_couche1 = (taille_filtre_couche1[0] * taille_filtre_couche1[1] * nombre_canaux_entree_couche1 + 1) * nombre_filtres_couche1\n",
    "\n",
    "nombre_filtres_couche2 = 16\n",
    "taille_filtre_couche2 = (3, 3)\n",
    "nombre_canaux_entree_couche2 = 8  # Nombre de filtres de la couche pr√©c√©dente\n",
    "nombre_parametres_couche2 = (taille_filtre_couche2[0] * taille_filtre_couche2[1] * nombre_canaux_entree_couche2 + 1) * nombre_filtres_couche2\n",
    "\n",
    "# Afficher le nombre total de param√®tres\n",
    "nombre_total_parametres = nombre_parametres_couche1 + nombre_parametres_couche2\n",
    "print(\"Nombre total de param√®tres dans le mod√®le :\", nombre_total_parametres)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": [
     "delete"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First Conv2D\n",
    "first_layer_weights = 8\n",
    "first_layer_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": [
     "delete"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Second Conv2D\n",
    "second_layer_weights = 16\n",
    "second_layer_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": [
     "delete"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Third Conv2D\n",
    "third_layer_weights = 7850\n",
    "third_layer_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": [
     "delete"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dense Layer\n",
    "dense_layer_weights = 110\n",
    "dense_layer_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": [
     "delete"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_number_of_weights = first_layer_weights + second_layer_weights + third_layer_weights + dense_layer_weights\n",
    "total_number_of_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.2) Training a CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question: training a CNN** ‚ùì \n",
    "\n",
    "Initialize your model and fit it on the train data. \n",
    "- Do not forget to use a **Validation Set/Split** and an **Early Stopping criterion**. \n",
    "- Limit yourself to 5 epochs max in this challenge, just to save some precious time for the more advanced challenges!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:From c:\\Users\\benoi\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\benoi\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1500/1500 [==============================] - 21s 10ms/step - loss: 0.3275 - accuracy: 0.8982 - val_loss: 0.1204 - val_accuracy: 0.9644\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 21s 14ms/step - loss: 0.1103 - accuracy: 0.9673 - val_loss: 0.1002 - val_accuracy: 0.9693\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0865 - accuracy: 0.9744 - val_loss: 0.0893 - val_accuracy: 0.9729\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0719 - accuracy: 0.9781 - val_loss: 0.0715 - val_accuracy: 0.9797\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 0.0615 - accuracy: 0.9805 - val_loss: 0.0593 - val_accuracy: 0.9833\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Initialiser le mod√®le\n",
    "cnn_model = initialize_model()\n",
    "\n",
    "# Compiler le mod√®le\n",
    "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# D√©finir la callback EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# Entra√Æner le mod√®le avec la validation et l'arr√™t pr√©coce\n",
    "history = cnn_model.fit(\n",
    "    X_train, y_train_cat,\n",
    "    epochs=5,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,  # 20% des donn√©es pour la validation\n",
    "    callbacks=[early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question: How many iterations does the CNN perform per epoch** ‚ùì\n",
    "\n",
    "_Note: it has nothing to do with the fact that this is a CNN. This is related to the concept of forward/backward propagation already covered during the previous lecture on optimizers, fitting, and losses üòâ_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "source": [
    "\n",
    "‚Äã\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><i>Answer</i></summary>\n",
    "\n",
    "With `verbose = 1` when fitting your model, you have access to crucial information about your training procedure.\n",
    "    \n",
    "Remember that we've just trained our CNN model on $60000$ training images\n",
    "\n",
    "If the chosen batch size is 32: \n",
    "\n",
    "* For each epoch, we have $ \\large \\lceil \\frac{60000}{32} \\rceil = 1875$ minibatches <br/>\n",
    "* The _validation_split_ is equal to $0.3$ - which means that within one single epoch, there are:\n",
    "    * $ \\lceil 1875 \\times (1 - 0.3) \\rceil = \\lceil 1312.5 \\rceil = 1313$ batches are used to compute the `train_loss` \n",
    "    * $ 1875 - 1312 = 562 $ batches are used to compute the `val_loss`\n",
    "    * **The parameters are updated 1313 times per epoch** as there are 1313 forward/backward propagations per epoch !!!\n",
    "\n",
    "\n",
    "üëâ With so many updates of the weights within one epoch, you can understand why this CNN model converges even with a limited number of epochs.\n",
    "\n",
    "</details>    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.3) Evaluating its performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question: Evaluating your CNN** ‚ùì \n",
    "\n",
    "What is your **`accuracy on the test set?`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test_preprocessed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Assuming cnn_model is your trained model and X_test_preprocessed, y_test_cat are your preprocessed test data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m results \u001b[38;5;241m=\u001b[39m cnn_model\u001b[38;5;241m.\u001b[39mevaluate(X_test_preprocessed, y_test_cat)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# The accuracy is usually the first value in the results list\u001b[39;00m\n\u001b[0;32m      5\u001b[0m test_accuracy \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test_preprocessed' is not defined"
     ]
    }
   ],
   "source": [
    "# Assuming cnn_model is your trained model and X_test_preprocessed, y_test_cat are your preprocessed test data\n",
    "results = cnn_model.evaluate(X_test_preprocessed, y_test_cat)\n",
    "\n",
    "# The accuracy is usually the first value in the results list\n",
    "test_accuracy = results[1]\n",
    "print(f\"Accuracy on the test set: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "üî• You solved what was a very hard problem 30 years ago with your own CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
